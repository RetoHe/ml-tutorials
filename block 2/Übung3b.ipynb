{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Übung 3b\n",
    "#### CNN für Cats und Dog Bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(\"../data/cats_vs_dogs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['valid', 'test', 'train']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.name for e in data_dir.glob(\"./*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: rename ../data/cats_vs_dogs/validation to ../data/cats_vs_dogs/valid/validation: No such file or directory\n",
      "mv: rename ../data/cats_vs_dogs/evaluation to ../data/cats_vs_dogs/test/evaluation: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!mv ../data/cats_vs_dogs/validation ../data/cats_vs_dogs/valid\n",
    "!mv ../data/cats_vs_dogs/evaluation ../data/cats_vs_dogs/test\n",
    "!rm -rf ../data/cats_vs_dogs/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['valid', 'test', 'train']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.name for e in data_dir.glob(\"./*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'dog']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_NAMES = [item.name for item in data_dir.glob('train/*')]\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = 5000\n",
    "\n",
    "train_cats = list(data_dir.glob('train/cat/*.jpg'))[:n_labels//2]\n",
    "train_dogs = list(data_dir.glob('train/dog/*.jpg'))[:n_labels//2]\n",
    "train_files = train_cats + train_dogs\n",
    "train_files = [str(x) for x in train_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.list_files(train_files)\n",
    "valid_ds = tf.data.Dataset.list_files(str(data_dir/'valid/*/*.jpg'))\n",
    "test_ds  = tf.data.Dataset.list_files(str(data_dir/'test/*/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    label = 1 if parts[-2] == \"dog\" else 0\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img, IMG_WIDTH=160, IMG_HEIGHT=160):\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = (img/127.5) - 1.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(process_path)\n",
    "valid_ds = valid_ds.map(process_path)\n",
    "test_ds  = test_ds.map(process_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    " \n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "valid_ds = valid_ds.batch(BATCH_SIZE)\n",
    "test_ds  = test_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das erste CNN besteht bei mir aus einem zweidimensionalen Convoluional Layer mit Pixelgröße 3x3. Darauf folgt ein Max Pooliny Layer mit Größe 4x4. Danach habe ich einen Leaky ReLu Layer eingebaut, gefolgt von einem Dropout Layer mit Rate 0,25. Danach flatte ich den Input und dann folgt noch ein Dense Layer mit der Sigmoid Aktivierungsfunktion. Vor dem Output Layer habe ich noch einen Dropout Layer mit Rate 0,5 eingebaut. Als Ouptut Layer habe ich einen Denselayer mit der Softmax Aktivierung gewählt, der mir die Wahrscheinlichkeite für Katze und Hund ausgibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [160, 160, 3]\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "#model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(keras.layers.LeakyReLU())\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='sigmoid'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "opt      = keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "loss_fct = keras.losses.sparse_categorical_crossentropy\n",
    "metrics  = [keras.metrics.sparse_categorical_accuracy]\n",
    "model.compile(optimizer=opt, loss=loss_fct, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 158, 158, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 39, 39, 32)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 39, 39, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 39, 39, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 48672)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               6230144   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 6,231,298\n",
      "Trainable params: 6,231,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 157 steps, validate for 157 steps\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 86s 547ms/step - loss: 0.7053 - sparse_categorical_accuracy: 0.5574 - val_loss: 0.6382 - val_sparse_categorical_accuracy: 0.6252\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 84s 536ms/step - loss: 0.6394 - sparse_categorical_accuracy: 0.6266 - val_loss: 0.6156 - val_sparse_categorical_accuracy: 0.6522\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 84s 536ms/step - loss: 0.6109 - sparse_categorical_accuracy: 0.6576 - val_loss: 0.5974 - val_sparse_categorical_accuracy: 0.6698\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 84s 534ms/step - loss: 0.5684 - sparse_categorical_accuracy: 0.6980 - val_loss: 0.5645 - val_sparse_categorical_accuracy: 0.7174\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 84s 536ms/step - loss: 0.5405 - sparse_categorical_accuracy: 0.7280 - val_loss: 0.5451 - val_sparse_categorical_accuracy: 0.7258\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 83s 532ms/step - loss: 0.5041 - sparse_categorical_accuracy: 0.7438 - val_loss: 0.5189 - val_sparse_categorical_accuracy: 0.7390\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 85s 540ms/step - loss: 0.4746 - sparse_categorical_accuracy: 0.7688 - val_loss: 0.5292 - val_sparse_categorical_accuracy: 0.7336\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 91s 582ms/step - loss: 0.4241 - sparse_categorical_accuracy: 0.8006 - val_loss: 0.5488 - val_sparse_categorical_accuracy: 0.7266\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 389s 2s/step - loss: 0.3867 - sparse_categorical_accuracy: 0.8268 - val_loss: 0.5393 - val_sparse_categorical_accuracy: 0.7400\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 86s 551ms/step - loss: 0.3521 - sparse_categorical_accuracy: 0.8442 - val_loss: 0.5405 - val_sparse_categorical_accuracy: 0.7432\n"
     ]
    }
   ],
   "source": [
    "cnn_train_hist_1 = model.fit(train_ds, validation_data=valid_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 180ms/step - loss: 0.5676 - sparse_categorical_accuracy: 0.7350\n"
     ]
    }
   ],
   "source": [
    "loss1, accuracy1 = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss: 0.57\n",
      "initial accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {:.2f}\".format(loss1))\n",
    "print(\"Test accuracy: {:.2f}\".format(accuracy1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch dieses CNN kommt ich auf eine Accuracy von 74%.\n",
    "Nun versuche ich noch ein weiteres CNN aufzubauen.\n",
    "Dies habe ich etwas abgeändert. Zu Beginn habe ich 2 Concoluional Layer, mit unterschiedlichen Größen und einmal der Tanh und einmal der ReLu Aktivierunsgfunktion. Gefolgt von einem Maxpooling, einem Dropout und einem Flatten Layer und dann kommt bereits der Output Layer, der gleichbleibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.Sequential()\n",
    "model2.add(keras.layers.Conv2D(64, (5, 5), activation='tanh', input_shape=input_shape))\n",
    "model2.add(keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "model2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(keras.layers.Dropout(0.25))\n",
    "model2.add(keras.layers.Flatten())\n",
    "#model2.add(keras.layers.Dense(16, activation='sigmoid'))\n",
    "#model2.add(keras.layers.Dropout(0.5))\n",
    "model2.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "opt2      = keras.optimizers.Adam()\n",
    "loss_fct2 = keras.losses.categorical_crossentropy\n",
    "metrics2  = [keras.metrics.sparse_categorical_accuracy]\n",
    "model2.compile(optimizer=opt2, loss=loss_fct2, metrics=metrics2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 156, 156, 64)      4864      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 155, 155, 32)      8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 77, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 77, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 189728)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 379458    \n",
      "=================================================================\n",
      "Total params: 392,546\n",
      "Trainable params: 392,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 157 steps, validate for 157 steps\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 385s 2s/step - loss: 5.2948 - sparse_categorical_accuracy: 0.5020 - val_loss: 13.5974 - val_sparse_categorical_accuracy: 0.4982\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 369s 2s/step - loss: 65.8578 - sparse_categorical_accuracy: 0.5002 - val_loss: 115.6653 - val_sparse_categorical_accuracy: 0.4580\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 376s 2s/step - loss: 267.2621 - sparse_categorical_accuracy: 0.4908 - val_loss: 379.1777 - val_sparse_categorical_accuracy: 0.5034\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 383s 2s/step - loss: 420.5625 - sparse_categorical_accuracy: 0.5004 - val_loss: 530.1227 - val_sparse_categorical_accuracy: 0.4978\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 417s 3s/step - loss: 728.6656 - sparse_categorical_accuracy: 0.4996 - val_loss: 1440.3544 - val_sparse_categorical_accuracy: 0.5026\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 385s 2s/step - loss: 839.4679 - sparse_categorical_accuracy: 0.5004 - val_loss: 462.7593 - val_sparse_categorical_accuracy: 0.5154\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 410s 3s/step - loss: 759.2194 - sparse_categorical_accuracy: 0.5014 - val_loss: 670.7491 - val_sparse_categorical_accuracy: 0.4868\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 400s 3s/step - loss: 1029.5442 - sparse_categorical_accuracy: 0.5008 - val_loss: 1415.9474 - val_sparse_categorical_accuracy: 0.4710\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 379s 2s/step - loss: 1278.7221 - sparse_categorical_accuracy: 0.5006 - val_loss: 3195.6355 - val_sparse_categorical_accuracy: 0.5028\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 356s 2s/step - loss: 1120.3588 - sparse_categorical_accuracy: 0.5020 - val_loss: 1375.8471 - val_sparse_categorical_accuracy: 0.4880\n"
     ]
    }
   ],
   "source": [
    "cnn_train_hist_2 = model2.fit(train_ds, validation_data=valid_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 3s 360ms/step - loss: 1235.0332 - sparse_categorical_accuracy: 0.5300\n"
     ]
    }
   ],
   "source": [
    "loss2, accuracy2 = model2.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss: 1235.03\n",
      "initial accuracy: 0.53\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {:.2f}\".format(loss2))\n",
    "print(\"Test accuracy: {:.2f}\".format(accuracy2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit diesem CNN erreiche deutlich schwächere Ergebnisse und komme nur auf eine TestAccuracy von 53 %.\n",
    "Nun erstelle ich noch ein drittes CNN, wieder mit etwas mehr Layern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.models.Sequential()\n",
    "model3.add(keras.layers.Conv2D(32, (3, 3), activation='tanh', input_shape=input_shape))\n",
    "#model3.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model3.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(keras.layers.LeakyReLU(alpha = 0.3))\n",
    "model3.add(keras.layers.Flatten())\n",
    "model3.add(keras.layers.Dropout(0.50))\n",
    "model3.add(keras.layers.Dense(128, activation='sigmoid'))\n",
    "model3.add(keras.layers.Dropout(0.5))\n",
    "model3.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "opt3      = keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "loss_fct3 = keras.losses.sparse_categorical_crossentropy\n",
    "metrics3  = [keras.metrics.sparse_categorical_accuracy]\n",
    "model3.compile(optimizer=opt3, loss=loss_fct3, metrics=metrics3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 158, 158, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 79, 79, 32)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 79, 79, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 199712)            0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 199712)            0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               25563264  \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 25,564,418\n",
      "Trainable params: 25,564,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 157 steps, validate for 157 steps\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 119s 759ms/step - loss: 0.6998 - sparse_categorical_accuracy: 0.5700 - val_loss: 0.6474 - val_sparse_categorical_accuracy: 0.6176\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 119s 757ms/step - loss: 0.6440 - sparse_categorical_accuracy: 0.6270 - val_loss: 0.6535 - val_sparse_categorical_accuracy: 0.6054\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 119s 760ms/step - loss: 0.6021 - sparse_categorical_accuracy: 0.6672 - val_loss: 0.5922 - val_sparse_categorical_accuracy: 0.6806\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 120s 765ms/step - loss: 0.5736 - sparse_categorical_accuracy: 0.7002 - val_loss: 0.5979 - val_sparse_categorical_accuracy: 0.6762\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 119s 758ms/step - loss: 0.5417 - sparse_categorical_accuracy: 0.7288 - val_loss: 0.5846 - val_sparse_categorical_accuracy: 0.6872\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 119s 755ms/step - loss: 0.5132 - sparse_categorical_accuracy: 0.7438 - val_loss: 0.5752 - val_sparse_categorical_accuracy: 0.6938\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 120s 762ms/step - loss: 0.4671 - sparse_categorical_accuracy: 0.7758 - val_loss: 0.5636 - val_sparse_categorical_accuracy: 0.7096\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 119s 758ms/step - loss: 0.4129 - sparse_categorical_accuracy: 0.8132 - val_loss: 0.5817 - val_sparse_categorical_accuracy: 0.7048\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 126s 803ms/step - loss: 0.3580 - sparse_categorical_accuracy: 0.8504 - val_loss: 0.6432 - val_sparse_categorical_accuracy: 0.6966\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 127s 811ms/step - loss: 0.2964 - sparse_categorical_accuracy: 0.8776 - val_loss: 0.6077 - val_sparse_categorical_accuracy: 0.7028\n"
     ]
    }
   ],
   "source": [
    "cnn_train_hist_3 = model3.fit(train_ds, validation_data=valid_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 167ms/step - loss: 0.5864 - sparse_categorical_accuracy: 0.7400\n"
     ]
    }
   ],
   "source": [
    "loss3, accuracy3 = model3.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss: 0.59\n",
      "initial accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {:.2f}\".format(loss3))\n",
    "print(\"Test accuracy: {:.2f}\".format(accuracy3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit konnte ich mein erstes CNN noch leicht verbessern auf 74%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
